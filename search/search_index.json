{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Spaton Your mobile phone is the most powerful controller. @Generated by DALL\u00b7E 3 in ChatGPT","title":"Spaton"},{"location":"#spaton","text":"Your mobile phone is the most powerful controller. @Generated by DALL\u00b7E 3 in ChatGPT","title":"Spaton"},{"location":"about/","text":"Spaton Spaton is the combination of spatial and baton . The idea behind Spaton is to use the sensors in mobile phone to control spatial audio compositions. The system supports multi-user connections and has the potential to be used in large-scale interactive sound installations. This is also as the final project of the Spatial Audio course in TUB so there are some code explaination in details. If you simply want to use this project, it's ok to ignore the Implementation section. Many thanks to Luzie Ahrens , who originally proposed this idea. 1. System Design 1.1 Signal Flow The users enter the website and then each log in as a client of Spaton system. The clients communicate with the server to get a role in the interactive composition. Then the clients send their sensor data to the server. The server summarizes all the sensor data from clients and broadcasts OSC messages to the sound engine. The sound engine generates or manipulates the sound based on the coming OSC messages and distributes the sound to the speaker array. 1.2 Tech Stack The Client & Server are developed based on javascript libraries. The Client part was written in React and the Server relies on Express.js . socket.io is the tool fo full duplex connection between the clients and the server. The server broadcasts OSC messages with help of the osc.js library. For now, there is no specific Sound Engine for the Spaton system. As long as the Sound Engine is capable of Receive OSC Messages. Generate audio signals (for sure). Do spatial panning The demo I created uses Max/MSP with the Spat library from IRCAM. There are still many other options like Reaper , IEM Plugins , Supercollider etc. The tests were holded in the TU Studio where equips a 21 channel ambisonic speaker array setup. 2. Sensors There are two types of sensor events supported for now namely deviceorientation and devicemotion . For each event there are three parameters. deviceorientation : alpha, beta, gamma devicemotion : x, y, z Please check the Web doscs for further explainations. More interesting events can be derived from these basic events, like the dection of mobile phone shake. Support for more sensor events are considered. 3. Code Structure client: the implementation code of the client part server: the implementation code of the server part patches: spatial audio compositions 4. Test Environment This project was tested by myself using Chrome and iPhone 10 . Currently there is no guarantee that it will work in other browsers and mobile phone models.","title":"About"},{"location":"about/#spaton","text":"Spaton is the combination of spatial and baton . The idea behind Spaton is to use the sensors in mobile phone to control spatial audio compositions. The system supports multi-user connections and has the potential to be used in large-scale interactive sound installations. This is also as the final project of the Spatial Audio course in TUB so there are some code explaination in details. If you simply want to use this project, it's ok to ignore the Implementation section. Many thanks to Luzie Ahrens , who originally proposed this idea.","title":"Spaton"},{"location":"about/#1-system-design","text":"","title":"1. System Design"},{"location":"about/#11-signal-flow","text":"The users enter the website and then each log in as a client of Spaton system. The clients communicate with the server to get a role in the interactive composition. Then the clients send their sensor data to the server. The server summarizes all the sensor data from clients and broadcasts OSC messages to the sound engine. The sound engine generates or manipulates the sound based on the coming OSC messages and distributes the sound to the speaker array.","title":"1.1 Signal Flow"},{"location":"about/#12-tech-stack","text":"The Client & Server are developed based on javascript libraries. The Client part was written in React and the Server relies on Express.js . socket.io is the tool fo full duplex connection between the clients and the server. The server broadcasts OSC messages with help of the osc.js library. For now, there is no specific Sound Engine for the Spaton system. As long as the Sound Engine is capable of Receive OSC Messages. Generate audio signals (for sure). Do spatial panning The demo I created uses Max/MSP with the Spat library from IRCAM. There are still many other options like Reaper , IEM Plugins , Supercollider etc. The tests were holded in the TU Studio where equips a 21 channel ambisonic speaker array setup.","title":"1.2 Tech Stack"},{"location":"about/#2-sensors","text":"There are two types of sensor events supported for now namely deviceorientation and devicemotion . For each event there are three parameters. deviceorientation : alpha, beta, gamma devicemotion : x, y, z Please check the Web doscs for further explainations. More interesting events can be derived from these basic events, like the dection of mobile phone shake. Support for more sensor events are considered.","title":"2. Sensors"},{"location":"about/#3-code-structure","text":"client: the implementation code of the client part server: the implementation code of the server part patches: spatial audio compositions","title":"3. Code Structure"},{"location":"about/#4-test-environment","text":"This project was tested by myself using Chrome and iPhone 10 . Currently there is no guarantee that it will work in other browsers and mobile phone models.","title":"4. Test Environment"},{"location":"demonstrations/","text":"Demonstrations 1. Lost in Tibet This is a very simple spatial soundscape I created to test the Spaton project. Besides the samples and Max patch, you still need extra files to run it. ValhallaSupermassive.vst: It's hard to find a good reverb effect in Max. You can download it free from the VALHALLA . You need to put the ValhallaSupermassive.vst file in the patch folder if the system vst folder doesn't add to search path nn~: Make sure you have nn~ external install. You need to put the nn~.mxo in the patch folder if you don't want to put in to the default Max external folder monks.ts: The Rave model to be loaded by the nn~ external. You can find the download page here . The original name is VCTK.ts . Please change it to monks.ts and put it into the same folder of the patch. Max/MSP Screenshot @Generated by DALL\u00b7E 3 in ChatGPT","title":"Demonstrations"},{"location":"demonstrations/#demonstrations","text":"","title":"Demonstrations"},{"location":"demonstrations/#1-lost-in-tibet","text":"This is a very simple spatial soundscape I created to test the Spaton project. Besides the samples and Max patch, you still need extra files to run it. ValhallaSupermassive.vst: It's hard to find a good reverb effect in Max. You can download it free from the VALHALLA . You need to put the ValhallaSupermassive.vst file in the patch folder if the system vst folder doesn't add to search path nn~: Make sure you have nn~ external install. You need to put the nn~.mxo in the patch folder if you don't want to put in to the default Max external folder monks.ts: The Rave model to be loaded by the nn~ external. You can find the download page here . The original name is VCTK.ts . Please change it to monks.ts and put it into the same folder of the patch. Max/MSP Screenshot @Generated by DALL\u00b7E 3 in ChatGPT","title":"1. Lost in Tibet"},{"location":"implementation/","text":"Implementation This section is intended primarily for course reports, and for someone interested in implementation details. Most people can ignore this section. 1 Client Client is implemented using React and uses the lightweight tachyons toolkit to process CSS. It uses socket.io-client to manage the websocket connection between client and server. Following js files in src folder are the main implementations: App.js : The starting point of client functionalities InfoBoard.js : Display the information according to status. For now this is just a static paragraph RouteCard.js : The implementation of route card object. It process the logic and visual feedback of route cards. RouteManager.js : Each route card equips a route manager object to deal with the communication with server using the client socket. WebEvents.js : The json file to save mobile phone sensor event information. configs.js : configs file stores the general configurations of client, e.g IP&Port The client intialize the socket at the very begining before render the frontend. At the beginning of rendering it sends a https request to the server to get the current state of routes, then uses the response data to set the RouteCards state. All route card components are rendered according this state. All states and style of the route card is defined by the data from server. The RouteCard component needs to process the click interaction. It will check if the permission to use DeviceMotionEvent has been granted. It will request the permission if still not granted. After the permission check, I will send message to the server to occupy or to release a route according to the connection state. The RouteCard will set the connection state based on the returned message from server. The corresponding route manager will start or stop sending messages to ther server according to the connection state. The route manager choose the callback functions for EventListener according to the Events field as explained in Usage section. 2 Server Server relies on Express.js to create the server. socket.io is the tool fo full duplex connection between the clients and the server. The server broadcasts OSC messages with help of the osc.js library. Following js files in src folder are the main implementations: server.js : All the main implementation is in the server.js file which includes Server Setup, Websockt Application, Https Application and OSC Application. configs.js : configs file stores the general configurations of client, e.g IP&Port utils.js : Some utility functions The server loads the preset when initialised. Then it setups the backend by creating express application, setting up https server, setting up websocket and listening to specific IP/Port. It also opens the udp port for broadcasting OSC messages. The server process messages from all socket from different clients. It creates a sperate socket channel when new connection established, and clean up the the occupied routes when disconnection detected. When the message to request occupy and release a route detected. The server looks up the state fields in the preset json to give corresponding feedbacks. The client keeps sending sensor data belongs a route. The server checks the socket id of all coming sensor data and process the data only when the socket.id matches the id in the state field. All accepted sensor data are then broadcasted using the udp port. 3. Limitations The implementation is still in a very early stage. It can only run inside specific LAN and there are still a lot of browsers and mobile phones to be tested. The implementation misses a robust throoughtout error control. The plan of the design was to make a seamless intergration from sensor data to spatial audio scenarios. But there is still a very loose connection between the sensor processign system and spatial sound system. The unidirectional OSC connection makes the system indistinguishable from normal OSC control software in some cases. A very insight thought pointed by Dr.Henrik von Coler is that the underutilisation of multi-user connections. Theoretically it's possible to involve huge amout of clients into spatial composition. However, the design logic limits the maximum number to the number of route card. 4. Future Work Personally, I remain optimistic about the potential of the system and will continue to work on subsequent iterations to improve it. Based on the shortcomings mentioned above, here are some possible directions for further design. Optimise the code to improve the ability to handle feedback for all types of web problems. The code should be optimised to provide a level of interaction that is expected from a web application. Re-engineer the way OSC addresses are organised and allow for automatic capacity management based on the information of the connected clients. Improve system integration by including feedback from the sound engine. Create OSC process template for all common audio engines Explore the ability to perform audio processing, especially spatial processing, directly on the server side in addition to OSC control signals.","title":"Implementation"},{"location":"implementation/#implementation","text":"This section is intended primarily for course reports, and for someone interested in implementation details. Most people can ignore this section.","title":"Implementation"},{"location":"implementation/#1-client","text":"Client is implemented using React and uses the lightweight tachyons toolkit to process CSS. It uses socket.io-client to manage the websocket connection between client and server. Following js files in src folder are the main implementations: App.js : The starting point of client functionalities InfoBoard.js : Display the information according to status. For now this is just a static paragraph RouteCard.js : The implementation of route card object. It process the logic and visual feedback of route cards. RouteManager.js : Each route card equips a route manager object to deal with the communication with server using the client socket. WebEvents.js : The json file to save mobile phone sensor event information. configs.js : configs file stores the general configurations of client, e.g IP&Port The client intialize the socket at the very begining before render the frontend. At the beginning of rendering it sends a https request to the server to get the current state of routes, then uses the response data to set the RouteCards state. All route card components are rendered according this state. All states and style of the route card is defined by the data from server. The RouteCard component needs to process the click interaction. It will check if the permission to use DeviceMotionEvent has been granted. It will request the permission if still not granted. After the permission check, I will send message to the server to occupy or to release a route according to the connection state. The RouteCard will set the connection state based on the returned message from server. The corresponding route manager will start or stop sending messages to ther server according to the connection state. The route manager choose the callback functions for EventListener according to the Events field as explained in Usage section.","title":"1 Client"},{"location":"implementation/#2-server","text":"Server relies on Express.js to create the server. socket.io is the tool fo full duplex connection between the clients and the server. The server broadcasts OSC messages with help of the osc.js library. Following js files in src folder are the main implementations: server.js : All the main implementation is in the server.js file which includes Server Setup, Websockt Application, Https Application and OSC Application. configs.js : configs file stores the general configurations of client, e.g IP&Port utils.js : Some utility functions The server loads the preset when initialised. Then it setups the backend by creating express application, setting up https server, setting up websocket and listening to specific IP/Port. It also opens the udp port for broadcasting OSC messages. The server process messages from all socket from different clients. It creates a sperate socket channel when new connection established, and clean up the the occupied routes when disconnection detected. When the message to request occupy and release a route detected. The server looks up the state fields in the preset json to give corresponding feedbacks. The client keeps sending sensor data belongs a route. The server checks the socket id of all coming sensor data and process the data only when the socket.id matches the id in the state field. All accepted sensor data are then broadcasted using the udp port.","title":"2 Server"},{"location":"implementation/#3-limitations","text":"The implementation is still in a very early stage. It can only run inside specific LAN and there are still a lot of browsers and mobile phones to be tested. The implementation misses a robust throoughtout error control. The plan of the design was to make a seamless intergration from sensor data to spatial audio scenarios. But there is still a very loose connection between the sensor processign system and spatial sound system. The unidirectional OSC connection makes the system indistinguishable from normal OSC control software in some cases. A very insight thought pointed by Dr.Henrik von Coler is that the underutilisation of multi-user connections. Theoretically it's possible to involve huge amout of clients into spatial composition. However, the design logic limits the maximum number to the number of route card.","title":"3. Limitations"},{"location":"implementation/#4-future-work","text":"Personally, I remain optimistic about the potential of the system and will continue to work on subsequent iterations to improve it. Based on the shortcomings mentioned above, here are some possible directions for further design. Optimise the code to improve the ability to handle feedback for all types of web problems. The code should be optimised to provide a level of interaction that is expected from a web application. Re-engineer the way OSC addresses are organised and allow for automatic capacity management based on the information of the connected clients. Improve system integration by including feedback from the sound engine. Create OSC process template for all common audio engines Explore the ability to perform audio processing, especially spatial processing, directly on the server side in addition to OSC control signals.","title":"4. Future Work"},{"location":"installation/","text":"Installation 1. Install npm & node.js Since the whole project is based on web technologies. Please make sure you have node.js and npm installed. Please check the npm Docs to get started with the Nearest Phase Modulator :) 2. Get the projects Simply clone the Spaton source code to your local machine. git clone git@github.com:zeyuyang42/Spaton.git cd Spaton 3. Create your own SSL certificate All sensor Web-API works only under https, SSL certificate are required to establish secure https connection. I recommend using OpenSSL to get a self-signed SSL certificate. There is a good reference guide . Or you can just follow the instruction below. mkdir sslcert cd sslcert openssl genrsa -out ${anynameyoulike}.key 2048 # generate private key openssl req \\ -newkey rsa:2048 -nodes -keyout ${anynameyoulike}.key \\ -x509 -days 365 -out ${anynameyoulike}.crt # generate certificate cd .. cp -r sslcert/ server/sslcert # copy the sslcert to server cp -r sslcert/ client/sslcert # copy the sslcert to client 4. Install packages Run npm install in server and client folder. 5. Change configs 5.1 Certificate Change the name of key and certificate if you don't use the name absinthismus . Server: change the sslcert and sslkey configure in the configs.js file. Client: Change the scirpt/start configure in the package.json file. 5.2 IP Change the configs.serverIP and configs.clientIP in each of the two configs.js files on the client and server from your current LAN IP. 5.3 Others You can customise the system to suit your composition. This part is elaborated in the Usage section. 6. Launch Run npm start to start server and client. You should see the following outputs when nothing goes wrong :) Client: Server:","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#1-install-npm-nodejs","text":"Since the whole project is based on web technologies. Please make sure you have node.js and npm installed. Please check the npm Docs to get started with the Nearest Phase Modulator :)","title":"1. Install npm &amp; node.js"},{"location":"installation/#2-get-the-projects","text":"Simply clone the Spaton source code to your local machine. git clone git@github.com:zeyuyang42/Spaton.git cd Spaton","title":"2. Get the projects"},{"location":"installation/#3-create-your-own-ssl-certificate","text":"All sensor Web-API works only under https, SSL certificate are required to establish secure https connection. I recommend using OpenSSL to get a self-signed SSL certificate. There is a good reference guide . Or you can just follow the instruction below. mkdir sslcert cd sslcert openssl genrsa -out ${anynameyoulike}.key 2048 # generate private key openssl req \\ -newkey rsa:2048 -nodes -keyout ${anynameyoulike}.key \\ -x509 -days 365 -out ${anynameyoulike}.crt # generate certificate cd .. cp -r sslcert/ server/sslcert # copy the sslcert to server cp -r sslcert/ client/sslcert # copy the sslcert to client","title":"3. Create your own SSL certificate"},{"location":"installation/#4-install-packages","text":"Run npm install in server and client folder.","title":"4. Install packages"},{"location":"installation/#5-change-configs","text":"","title":"5. Change configs"},{"location":"installation/#51-certificate","text":"Change the name of key and certificate if you don't use the name absinthismus . Server: change the sslcert and sslkey configure in the configs.js file. Client: Change the scirpt/start configure in the package.json file.","title":"5.1 Certificate"},{"location":"installation/#52-ip","text":"Change the configs.serverIP and configs.clientIP in each of the two configs.js files on the client and server from your current LAN IP.","title":"5.2 IP"},{"location":"installation/#53-others","text":"You can customise the system to suit your composition. This part is elaborated in the Usage section.","title":"5.3 Others"},{"location":"installation/#6-launch","text":"Run npm start to start server and client. You should see the following outputs when nothing goes wrong :) Client: Server:","title":"6. Launch"},{"location":"usage/","text":"Usage Ensure that you have completed the installation process and are able to successfully launch the client and server. 1. Client Interaction 1.1 Connection Make sure your phone is in the same network with the servers (Maybe just your Laptop in this early stage). View the Client in the Browser according to the following url. Please don't use the localhost. \ud83d\udea8 There would be a security warning from the brower for the first time login. Since we are using a self-signed ssl certificate instead of being issued by an trusted authority. You can ignore this and keep logging in if you believe in yourself :) 1.2 UI The Client UI looks as follow. The main functional parts are the listed route cards. Each route card represents a route for the client to choose. Blue cards are still available route. Red cards are choosen by this client. Grey cards with strikethrough means these routes are already occupied by other clients. Each route requires a list of sensor data. One client can choose multiply routes together. 2. Demo Listening You can experience the Spaton system using the demo patch I created. Take look at the Lost in Tibet in the patches folder for guidance of how to set it up. 3. Presets 3.1 Example Sure you will soon get bored if Spaton is only capable of supporting one specific composition. Luckily you can create presets for your own compositions. The route cards in the client UI are created orignally based on the preset data provided by the server looks as follow. Take a look at the Details section for better understanding (Later). [ { \"id\": 1, \"name\": \"ambientVol\", \"events\": [2], \"occupied\": false, \"client\": \"undefined\" }, { \"id\": 2, \"name\": \"walkOnSand\", \"events\": [1, 2], \"occupied\": false, \"client\": \"undefined\" }, { \"id\": 3, \"name\": \"monksTimbre\", \"events\": [1, 2, 3, 4, 5, 6], \"occupied\": false, \"client\": \"undefined\" }, { \"id\": 4, \"name\": \"tibetanBells\", \"events\": [4, 5, 6], \"occupied\": false, \"client\": \"undefined\" }, { \"id\": 5, \"name\": \"glitch\", \"events\": [3], \"occupied\": false, \"client\": \"undefined\" }, { \"id\": 6, \"name\": \"monksVolPos\", \"events\": [1, 2], \"occupied\": false, \"client\": \"undefined\" } ] 3.2 Create Preset You can create and use your own preset file. The preset files saved in the presets folder inside server folder where you can add your own json files. 3.2.1 JSON Fields Each route card is defined using the same fields: id : serial id of route card as identifier name : the name to display on the route card events : The list of mobile phone sensor events in this route. See Events section for details occupied : indicator for whether the route has been occupied client : save the client id if route is occupied 3.2.2 Events The numbers in the events list of preset json present different sensor parameters. These are defined in the WebEvents.js file inside the client . Please check the code for complete fields. The basic fields listed as below: Id Event Parameter 1 deviceorientation alpha 2 deviceorientation beta 3 deviceorientation gamma 4 devicemotion x 5 devicemotion y 6 devicemotion z 3.3 Use Preset To start the server with a specific preset file, please set the configs.presetAddress in the configs.js of the server. 4. OSC messages \ud83d\udea8 The OSC message formation is far from satisfied. It is going to be modified/improved in the following version! The address pattern of OSC message is formatted in the structure of : / ${routeName} / ${parameterName} e.g The route walkOnSand requires the events 1 and 2, which is the alpha and beta of device orientation event. The formatted message head looks like: /walkOnSand/alpha /walkOnSand/beta While the argument is the original orientation value along this axis without scale. You can receive OSC messages according to these address in the sound engine and use it to complete your composition. 5. Spatialization I won't give any tutorial of how to make spatial audio composition. But there are some basic ideas I tried and thought of when playing with the mobile phone sensors. Use the deviceorientation parameters to control the sound object position Use the devicemotion to control the moving speed of object Use the not with spatialisation connected parameter to control other sound parameters Shake the mobile phone to spatial granularize a material. (Tried, but my spatial granular patch is too computational inefficient ) ...","title":"Usage"},{"location":"usage/#usage","text":"Ensure that you have completed the installation process and are able to successfully launch the client and server.","title":"Usage"},{"location":"usage/#1-client-interaction","text":"","title":"1. Client Interaction"},{"location":"usage/#11-connection","text":"Make sure your phone is in the same network with the servers (Maybe just your Laptop in this early stage). View the Client in the Browser according to the following url. Please don't use the localhost. \ud83d\udea8 There would be a security warning from the brower for the first time login. Since we are using a self-signed ssl certificate instead of being issued by an trusted authority. You can ignore this and keep logging in if you believe in yourself :)","title":"1.1 Connection"},{"location":"usage/#12-ui","text":"The Client UI looks as follow. The main functional parts are the listed route cards. Each route card represents a route for the client to choose. Blue cards are still available route. Red cards are choosen by this client. Grey cards with strikethrough means these routes are already occupied by other clients. Each route requires a list of sensor data. One client can choose multiply routes together.","title":"1.2 UI"},{"location":"usage/#2-demo-listening","text":"You can experience the Spaton system using the demo patch I created. Take look at the Lost in Tibet in the patches folder for guidance of how to set it up.","title":"2. Demo Listening"},{"location":"usage/#3-presets","text":"","title":"3. Presets"},{"location":"usage/#31-example","text":"Sure you will soon get bored if Spaton is only capable of supporting one specific composition. Luckily you can create presets for your own compositions. The route cards in the client UI are created orignally based on the preset data provided by the server looks as follow. Take a look at the Details section for better understanding (Later). [ { \"id\": 1, \"name\": \"ambientVol\", \"events\": [2], \"occupied\": false, \"client\": \"undefined\" }, { \"id\": 2, \"name\": \"walkOnSand\", \"events\": [1, 2], \"occupied\": false, \"client\": \"undefined\" }, { \"id\": 3, \"name\": \"monksTimbre\", \"events\": [1, 2, 3, 4, 5, 6], \"occupied\": false, \"client\": \"undefined\" }, { \"id\": 4, \"name\": \"tibetanBells\", \"events\": [4, 5, 6], \"occupied\": false, \"client\": \"undefined\" }, { \"id\": 5, \"name\": \"glitch\", \"events\": [3], \"occupied\": false, \"client\": \"undefined\" }, { \"id\": 6, \"name\": \"monksVolPos\", \"events\": [1, 2], \"occupied\": false, \"client\": \"undefined\" } ]","title":"3.1 Example"},{"location":"usage/#32-create-preset","text":"You can create and use your own preset file. The preset files saved in the presets folder inside server folder where you can add your own json files.","title":"3.2 Create Preset"},{"location":"usage/#321-json-fields","text":"Each route card is defined using the same fields: id : serial id of route card as identifier name : the name to display on the route card events : The list of mobile phone sensor events in this route. See Events section for details occupied : indicator for whether the route has been occupied client : save the client id if route is occupied","title":"3.2.1 JSON Fields"},{"location":"usage/#322-events","text":"The numbers in the events list of preset json present different sensor parameters. These are defined in the WebEvents.js file inside the client . Please check the code for complete fields. The basic fields listed as below: Id Event Parameter 1 deviceorientation alpha 2 deviceorientation beta 3 deviceorientation gamma 4 devicemotion x 5 devicemotion y 6 devicemotion z","title":"3.2.2 Events"},{"location":"usage/#33-use-preset","text":"To start the server with a specific preset file, please set the configs.presetAddress in the configs.js of the server.","title":"3.3 Use Preset"},{"location":"usage/#4-osc-messages","text":"\ud83d\udea8 The OSC message formation is far from satisfied. It is going to be modified/improved in the following version! The address pattern of OSC message is formatted in the structure of : / ${routeName} / ${parameterName} e.g The route walkOnSand requires the events 1 and 2, which is the alpha and beta of device orientation event. The formatted message head looks like: /walkOnSand/alpha /walkOnSand/beta While the argument is the original orientation value along this axis without scale. You can receive OSC messages according to these address in the sound engine and use it to complete your composition.","title":"4. OSC messages"},{"location":"usage/#5-spatialization","text":"I won't give any tutorial of how to make spatial audio composition. But there are some basic ideas I tried and thought of when playing with the mobile phone sensors. Use the deviceorientation parameters to control the sound object position Use the devicemotion to control the moving speed of object Use the not with spatialisation connected parameter to control other sound parameters Shake the mobile phone to spatial granularize a material. (Tried, but my spatial granular patch is too computational inefficient ) ...","title":"5. Spatialization"}]}